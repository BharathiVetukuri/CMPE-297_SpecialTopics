# ğŸ“˜ Continued Pretraining

This README summarizes the **visible result cells** for your Continued Pretraining (Colab 5) notebook.  

---
# Artifacts

**ğŸ“˜ Colab Notebook:** https://colab.research.google.com/drive/1jOhaRfygFFaJ0ZCPWwAiMFGk3FwS_1d4?usp=sharing 

**ğŸ“¹ Demo Video:**

---

## âœ… What This Section Shows
- A quick **peek at training samples** (what the model learned from).
- **Side-by-side outputs**: Base model vs. Continued-pretrained (LoRA) model on French prompts.
- An **empathetic assistant demo** (useful if you used a mental-health or support tone dataset).
- A tiny **fluency proxy** (response length + accented characters) to visualize language adaptation.

---

## â–¶ï¸ How To Use
1. Run your training steps (through saving the continued-pretrained model).
2. Add the four visibility cells **after training**.
3. Execute them in order to print comparison outputs in the notebook.

---

## ğŸ” Cells Included

### 1) Sample Preview â€” What the Model Saw
**Cell:** *Preview 3 samples from the training corpus*  
**Purpose:** Shows representative text pairs used in continued pretraining.

### 2) Base vs Continued â€” French Prompts
**Cell:** *Compare BASE vs CONTINUED model outputs on French prompts*  
**Purpose:** Demonstrates clearer, more natural French or better adherence to prompts after continued pretraining.

### 3) Empathetic Assistant Demo (Optional)
**Cell:** *Short empathetic response in French (or your target domain/language)*  
**Purpose:** Showcases tone/style gains (e.g., counseling or supportive phrasing).

### 4) Tiny Fluency Proxy (Optional)
**Cell:** *Length & accented-character count*  
**Purpose:** A quick, non-scientific proxy indicating more fluent, longer, or accent-rich responses after training.

---

## ğŸ§ª Example Prompts Used
- â€œ**Traduisez en franÃ§ais**: â€˜The cat sits on the mat and watches the sunset.â€™â€
- â€œ**Explique en franÃ§ais**, en 2 phrases, la diffÃ©rence entre une **liste** et un **tuple** en Python.â€
- â€œ**Ã‰cris une brÃ¨ve description poÃ©tique** dâ€™un matin pluvieux Ã  Paris (2â€“3 phrases).â€
- **Empathetic** support prompt in French for mental-health style guidance.

---

## ğŸ“‚ Files Produced
- `continued_pretrain_model/` â€” your continued-pretrained model (adapters + tokenizer).
- This README â€” `README_ContinuedPretraining_Results.md`.

---

## ğŸ”— References
- Unsloth.ai â€” **Continued Pretraining** (basics)
- Unsloth.ai â€” **Export to Ollama** tutorial

---

## Screenshots

<img width="860" height="530" alt="image" src="https://github.com/user-attachments/assets/40507780-1bdf-4a61-add7-66d6d1877577" />

<img width="860" height="538" alt="image" src="https://github.com/user-attachments/assets/f47cec48-3a7e-47fe-b417-28131e632439" />


<img width="860" height="538" alt="image" src="https://github.com/user-attachments/assets/26eec5b6-8e69-458b-85fc-dc4b0502e6b4" />

